{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d6d0ec-da7a-4c77-ac7a-2ce2e9d9e9d4",
   "metadata": {},
   "source": [
    "The goal of this project is to test mulitple type of regression models using different frameworks like SKLearn, StatModels, and TensorFlow. This data represents detection of credit card fraud\n",
    "using different metrics represented by V1 - V28 to identify fraudulent transactions. The Class column represents if the transaction was identified as fraud (Class = 1) or not (Class = 0)\n",
    "\n",
    "The csv can be found at this URL:\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f3058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b90ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
       "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
       "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
       "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
       "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4  1.071126  0.023712  0.419117  14278.97      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('creditcard_2023.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc8cc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568630.000000</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>5.686300e+05</td>\n",
       "      <td>568630.000000</td>\n",
       "      <td>568630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284314.500000</td>\n",
       "      <td>-5.638058e-17</td>\n",
       "      <td>-1.319545e-16</td>\n",
       "      <td>-3.518788e-17</td>\n",
       "      <td>-2.879008e-17</td>\n",
       "      <td>7.997245e-18</td>\n",
       "      <td>-3.958636e-17</td>\n",
       "      <td>-3.198898e-17</td>\n",
       "      <td>2.109273e-17</td>\n",
       "      <td>3.998623e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.758361e-17</td>\n",
       "      <td>3.948640e-18</td>\n",
       "      <td>6.194741e-18</td>\n",
       "      <td>-2.799036e-18</td>\n",
       "      <td>-3.178905e-17</td>\n",
       "      <td>-7.497417e-18</td>\n",
       "      <td>-3.598760e-17</td>\n",
       "      <td>2.609101e-17</td>\n",
       "      <td>12041.957635</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164149.486121</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>6919.644449</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.495584e+00</td>\n",
       "      <td>-4.996657e+01</td>\n",
       "      <td>-3.183760e+00</td>\n",
       "      <td>-4.951222e+00</td>\n",
       "      <td>-9.952786e+00</td>\n",
       "      <td>-2.111111e+01</td>\n",
       "      <td>-4.351839e+00</td>\n",
       "      <td>-1.075634e+01</td>\n",
       "      <td>-3.751919e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.938252e+01</td>\n",
       "      <td>-7.734798e+00</td>\n",
       "      <td>-3.029545e+01</td>\n",
       "      <td>-4.067968e+00</td>\n",
       "      <td>-1.361263e+01</td>\n",
       "      <td>-8.226969e+00</td>\n",
       "      <td>-1.049863e+01</td>\n",
       "      <td>-3.903524e+01</td>\n",
       "      <td>50.010000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142157.250000</td>\n",
       "      <td>-5.652859e-01</td>\n",
       "      <td>-4.866777e-01</td>\n",
       "      <td>-6.492987e-01</td>\n",
       "      <td>-6.560203e-01</td>\n",
       "      <td>-2.934955e-01</td>\n",
       "      <td>-4.458712e-01</td>\n",
       "      <td>-2.835329e-01</td>\n",
       "      <td>-1.922572e-01</td>\n",
       "      <td>-5.687446e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.664408e-01</td>\n",
       "      <td>-4.904892e-01</td>\n",
       "      <td>-2.376289e-01</td>\n",
       "      <td>-6.515801e-01</td>\n",
       "      <td>-5.541485e-01</td>\n",
       "      <td>-6.318948e-01</td>\n",
       "      <td>-3.049607e-01</td>\n",
       "      <td>-2.318783e-01</td>\n",
       "      <td>6054.892500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284314.500000</td>\n",
       "      <td>-9.363846e-02</td>\n",
       "      <td>-1.358939e-01</td>\n",
       "      <td>3.528579e-04</td>\n",
       "      <td>-7.376152e-02</td>\n",
       "      <td>8.108788e-02</td>\n",
       "      <td>7.871758e-02</td>\n",
       "      <td>2.333659e-01</td>\n",
       "      <td>-1.145242e-01</td>\n",
       "      <td>9.252647e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.743065e-02</td>\n",
       "      <td>-2.732881e-02</td>\n",
       "      <td>-5.968903e-02</td>\n",
       "      <td>1.590123e-02</td>\n",
       "      <td>-8.193162e-03</td>\n",
       "      <td>-1.189208e-02</td>\n",
       "      <td>-1.729111e-01</td>\n",
       "      <td>-1.392973e-02</td>\n",
       "      <td>12030.150000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426471.750000</td>\n",
       "      <td>8.326582e-01</td>\n",
       "      <td>3.435552e-01</td>\n",
       "      <td>6.285380e-01</td>\n",
       "      <td>7.070047e-01</td>\n",
       "      <td>4.397368e-01</td>\n",
       "      <td>4.977881e-01</td>\n",
       "      <td>5.259548e-01</td>\n",
       "      <td>4.729905e-02</td>\n",
       "      <td>5.592621e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479787e-01</td>\n",
       "      <td>4.638817e-01</td>\n",
       "      <td>1.557153e-01</td>\n",
       "      <td>7.007374e-01</td>\n",
       "      <td>5.500147e-01</td>\n",
       "      <td>6.728879e-01</td>\n",
       "      <td>3.340230e-01</td>\n",
       "      <td>4.095903e-01</td>\n",
       "      <td>18036.330000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568629.000000</td>\n",
       "      <td>2.229046e+00</td>\n",
       "      <td>4.361865e+00</td>\n",
       "      <td>1.412583e+01</td>\n",
       "      <td>3.201536e+00</td>\n",
       "      <td>4.271689e+01</td>\n",
       "      <td>2.616840e+01</td>\n",
       "      <td>2.178730e+02</td>\n",
       "      <td>5.958040e+00</td>\n",
       "      <td>2.027006e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.087080e+00</td>\n",
       "      <td>1.263251e+01</td>\n",
       "      <td>3.170763e+01</td>\n",
       "      <td>1.296564e+01</td>\n",
       "      <td>1.462151e+01</td>\n",
       "      <td>5.623285e+00</td>\n",
       "      <td>1.132311e+02</td>\n",
       "      <td>7.725594e+01</td>\n",
       "      <td>24039.930000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            V1            V2            V3            V4  \\\n",
       "count  568630.000000  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
       "mean   284314.500000 -5.638058e-17 -1.319545e-16 -3.518788e-17 -2.879008e-17   \n",
       "std    164149.486121  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min         0.000000 -3.495584e+00 -4.996657e+01 -3.183760e+00 -4.951222e+00   \n",
       "25%    142157.250000 -5.652859e-01 -4.866777e-01 -6.492987e-01 -6.560203e-01   \n",
       "50%    284314.500000 -9.363846e-02 -1.358939e-01  3.528579e-04 -7.376152e-02   \n",
       "75%    426471.750000  8.326582e-01  3.435552e-01  6.285380e-01  7.070047e-01   \n",
       "max    568629.000000  2.229046e+00  4.361865e+00  1.412583e+01  3.201536e+00   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
       "mean   7.997245e-18 -3.958636e-17 -3.198898e-17  2.109273e-17  3.998623e-17   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -9.952786e+00 -2.111111e+01 -4.351839e+00 -1.075634e+01 -3.751919e+00   \n",
       "25%   -2.934955e-01 -4.458712e-01 -2.835329e-01 -1.922572e-01 -5.687446e-01   \n",
       "50%    8.108788e-02  7.871758e-02  2.333659e-01 -1.145242e-01  9.252647e-02   \n",
       "75%    4.397368e-01  4.977881e-01  5.259548e-01  4.729905e-02  5.592621e-01   \n",
       "max    4.271689e+01  2.616840e+01  2.178730e+02  5.958040e+00  2.027006e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
       "mean   ...  4.758361e-17  3.948640e-18  6.194741e-18 -2.799036e-18   \n",
       "std    ...  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min    ... -1.938252e+01 -7.734798e+00 -3.029545e+01 -4.067968e+00   \n",
       "25%    ... -1.664408e-01 -4.904892e-01 -2.376289e-01 -6.515801e-01   \n",
       "50%    ... -3.743065e-02 -2.732881e-02 -5.968903e-02  1.590123e-02   \n",
       "75%    ...  1.479787e-01  4.638817e-01  1.557153e-01  7.007374e-01   \n",
       "max    ...  8.087080e+00  1.263251e+01  3.170763e+01  1.296564e+01   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05  568630.000000   \n",
       "mean  -3.178905e-17 -7.497417e-18 -3.598760e-17  2.609101e-17   12041.957635   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00    6919.644449   \n",
       "min   -1.361263e+01 -8.226969e+00 -1.049863e+01 -3.903524e+01      50.010000   \n",
       "25%   -5.541485e-01 -6.318948e-01 -3.049607e-01 -2.318783e-01    6054.892500   \n",
       "50%   -8.193162e-03 -1.189208e-02 -1.729111e-01 -1.392973e-02   12030.150000   \n",
       "75%    5.500147e-01  6.728879e-01  3.340230e-01  4.095903e-01   18036.330000   \n",
       "max    1.462151e+01  5.623285e+00  1.132311e+02  7.725594e+01   24039.930000   \n",
       "\n",
       "          Class  \n",
       "count  568630.0  \n",
       "mean        0.5  \n",
       "std         0.5  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.5  \n",
       "75%         1.0  \n",
       "max         1.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc2a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568630 entries, 0 to 568629\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      568630 non-null  int64  \n",
      " 1   V1      568630 non-null  float64\n",
      " 2   V2      568630 non-null  float64\n",
      " 3   V3      568630 non-null  float64\n",
      " 4   V4      568630 non-null  float64\n",
      " 5   V5      568630 non-null  float64\n",
      " 6   V6      568630 non-null  float64\n",
      " 7   V7      568630 non-null  float64\n",
      " 8   V8      568630 non-null  float64\n",
      " 9   V9      568630 non-null  float64\n",
      " 10  V10     568630 non-null  float64\n",
      " 11  V11     568630 non-null  float64\n",
      " 12  V12     568630 non-null  float64\n",
      " 13  V13     568630 non-null  float64\n",
      " 14  V14     568630 non-null  float64\n",
      " 15  V15     568630 non-null  float64\n",
      " 16  V16     568630 non-null  float64\n",
      " 17  V17     568630 non-null  float64\n",
      " 18  V18     568630 non-null  float64\n",
      " 19  V19     568630 non-null  float64\n",
      " 20  V20     568630 non-null  float64\n",
      " 21  V21     568630 non-null  float64\n",
      " 22  V22     568630 non-null  float64\n",
      " 23  V23     568630 non-null  float64\n",
      " 24  V24     568630 non-null  float64\n",
      " 25  V25     568630 non-null  float64\n",
      " 26  V26     568630 non-null  float64\n",
      " 27  V27     568630 non-null  float64\n",
      " 28  V28     568630 non-null  float64\n",
      " 29  Amount  568630 non-null  float64\n",
      " 30  Class   568630 non-null  int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 134.5 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d1c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum() # No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d2fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 568630\n",
      "Class 1: 284315\n",
      "Class 0: 284315\n"
     ]
    }
   ],
   "source": [
    "# Checking for how many observations each class has\n",
    "print('Data Size:', raw_data['Class'].size)\n",
    "print('Class 1:', raw_data['Class'].sum())\n",
    "print('Class 0:', raw_data['Class'].size - raw_data['Class'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b08975f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.637735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>0.690708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.968046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.130006  0.727159  0.637735  ... -0.110552  0.217606 -0.134794  0.165959   \n",
       "1 -0.133118  0.347452  0.529808  ... -0.194936 -0.605761  0.079469 -0.577395   \n",
       "2 -0.095576 -0.261297  0.690708  ... -0.005020  0.702906  0.945045 -1.154666   \n",
       "3 -0.065130 -0.205698  0.575231  ... -0.146927 -0.038212 -0.214048 -1.893131   \n",
       "4 -0.212660  1.049921  0.968046  ... -0.106984  0.729727 -0.161666  0.312561   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.126280 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.190090  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.605564 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3  1.003963 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4 -0.414116  1.071126  0.023712  0.419117  14278.97      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped_id = raw_data.copy() # Checkpoint - Dropping ID feature\n",
    "df_dropped_id = df_dropped_id.drop('id', axis = 1) # Id is not a feature that impacts dependent variable\n",
    "df_dropped_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b2aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1 - V-28 already appear to be scaled\n",
    "# Amount has drastically higher values then the rest of the features, lets scale them so they do not overly influence the model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cdc34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.637735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>0.858447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>-0.796369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>0.690708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>-1.377011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-0.962119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.968046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>0.323285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.130006  0.727159  0.637735  ... -0.110552  0.217606 -0.134794  0.165959   \n",
       "1 -0.133118  0.347452  0.529808  ... -0.194936 -0.605761  0.079469 -0.577395   \n",
       "2 -0.095576 -0.261297  0.690708  ... -0.005020  0.702906  0.945045 -1.154666   \n",
       "3 -0.065130 -0.205698  0.575231  ... -0.146927 -0.038212 -0.214048 -1.893131   \n",
       "4 -0.212660  1.049921  0.968046  ... -0.106984  0.729727 -0.161666  0.312561   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.126280 -0.434824 -0.081230 -0.151045  0.858447      0  \n",
       "1  0.190090  0.296503 -0.248052 -0.064512 -0.796369      0  \n",
       "2 -0.605564 -0.312895 -0.300258 -0.244718 -1.377011      0  \n",
       "3  1.003963 -0.515950 -0.165316  0.048424 -0.962119      0  \n",
       "4 -0.414116  1.071126  0.023712  0.419117  0.323285      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled_amount = df_dropped_id.copy() # Checkpoint - Scaling Amount Feature\n",
    "df_scaled_amount['Amount'] = scaler.fit_transform(df_scaled_amount[['Amount']].values) # Scale just the amount column\n",
    "df_scaled_amount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd86aec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.637735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091202</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>0.858447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233984</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>-0.796369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>0.690708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361652</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>-1.377011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378223</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>-0.962119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.968046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247237</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>0.323285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568625</th>\n",
       "      <td>-0.833437</td>\n",
       "      <td>0.061886</td>\n",
       "      <td>-0.899794</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-1.002401</td>\n",
       "      <td>0.481454</td>\n",
       "      <td>-0.370393</td>\n",
       "      <td>0.189694</td>\n",
       "      <td>-0.938153</td>\n",
       "      <td>-1.161847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.751011</td>\n",
       "      <td>0.167503</td>\n",
       "      <td>0.419731</td>\n",
       "      <td>1.288249</td>\n",
       "      <td>-0.900861</td>\n",
       "      <td>0.560661</td>\n",
       "      <td>-0.006018</td>\n",
       "      <td>3.308968</td>\n",
       "      <td>0.081564</td>\n",
       "      <td>-1.105231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568626</th>\n",
       "      <td>-0.670459</td>\n",
       "      <td>-0.202896</td>\n",
       "      <td>-0.068129</td>\n",
       "      <td>-0.267328</td>\n",
       "      <td>-0.133660</td>\n",
       "      <td>0.237148</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-0.147733</td>\n",
       "      <td>0.483894</td>\n",
       "      <td>-0.210817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.550260</td>\n",
       "      <td>0.031874</td>\n",
       "      <td>0.388161</td>\n",
       "      <td>-0.154257</td>\n",
       "      <td>-0.846452</td>\n",
       "      <td>-0.153443</td>\n",
       "      <td>1.961398</td>\n",
       "      <td>-1.528642</td>\n",
       "      <td>1.704306</td>\n",
       "      <td>-1.067766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568627</th>\n",
       "      <td>-0.311997</td>\n",
       "      <td>-0.004095</td>\n",
       "      <td>0.137526</td>\n",
       "      <td>-0.035893</td>\n",
       "      <td>-0.042291</td>\n",
       "      <td>0.121098</td>\n",
       "      <td>-0.070958</td>\n",
       "      <td>-0.019997</td>\n",
       "      <td>-0.122048</td>\n",
       "      <td>-0.144495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076417</td>\n",
       "      <td>0.140788</td>\n",
       "      <td>0.536523</td>\n",
       "      <td>-0.211100</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>0.540073</td>\n",
       "      <td>-0.755836</td>\n",
       "      <td>-0.487540</td>\n",
       "      <td>-0.268741</td>\n",
       "      <td>1.666401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568628</th>\n",
       "      <td>0.636871</td>\n",
       "      <td>-0.516970</td>\n",
       "      <td>-0.300889</td>\n",
       "      <td>-0.144480</td>\n",
       "      <td>0.131042</td>\n",
       "      <td>-0.294148</td>\n",
       "      <td>0.580568</td>\n",
       "      <td>-0.207723</td>\n",
       "      <td>0.893527</td>\n",
       "      <td>-0.080078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288186</td>\n",
       "      <td>-0.060381</td>\n",
       "      <td>-0.195609</td>\n",
       "      <td>-0.175488</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>-0.099669</td>\n",
       "      <td>-1.434931</td>\n",
       "      <td>-0.159269</td>\n",
       "      <td>-0.076251</td>\n",
       "      <td>-0.271853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568629</th>\n",
       "      <td>-0.795144</td>\n",
       "      <td>0.433236</td>\n",
       "      <td>-0.649140</td>\n",
       "      <td>0.374732</td>\n",
       "      <td>-0.244976</td>\n",
       "      <td>-0.603493</td>\n",
       "      <td>-0.347613</td>\n",
       "      <td>-0.340814</td>\n",
       "      <td>0.253971</td>\n",
       "      <td>-0.513556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621378</td>\n",
       "      <td>0.534853</td>\n",
       "      <td>-0.291514</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.931030</td>\n",
       "      <td>-0.349423</td>\n",
       "      <td>-1.090974</td>\n",
       "      <td>-1.575113</td>\n",
       "      <td>0.722936</td>\n",
       "      <td>1.365962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568630 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1       0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2      -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3      -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4      -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "568625 -0.833437  0.061886 -0.899794  0.904227 -1.002401  0.481454 -0.370393   \n",
       "568626 -0.670459 -0.202896 -0.068129 -0.267328 -0.133660  0.237148 -0.016935   \n",
       "568627 -0.311997 -0.004095  0.137526 -0.035893 -0.042291  0.121098 -0.070958   \n",
       "568628  0.636871 -0.516970 -0.300889 -0.144480  0.131042 -0.294148  0.580568   \n",
       "568629 -0.795144  0.433236 -0.649140  0.374732 -0.244976 -0.603493 -0.347613   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0      -0.130006  0.727159  0.637735  ...  0.091202 -0.110552  0.217606   \n",
       "1      -0.133118  0.347452  0.529808  ... -0.233984 -0.194936 -0.605761   \n",
       "2      -0.095576 -0.261297  0.690708  ...  0.361652 -0.005020  0.702906   \n",
       "3      -0.065130 -0.205698  0.575231  ... -0.378223 -0.146927 -0.038212   \n",
       "4      -0.212660  1.049921  0.968046  ...  0.247237 -0.106984  0.729727   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "568625  0.189694 -0.938153 -1.161847  ... -0.751011  0.167503  0.419731   \n",
       "568626 -0.147733  0.483894 -0.210817  ... -0.550260  0.031874  0.388161   \n",
       "568627 -0.019997 -0.122048 -0.144495  ... -0.076417  0.140788  0.536523   \n",
       "568628 -0.207723  0.893527 -0.080078  ...  0.288186 -0.060381 -0.195609   \n",
       "568629 -0.340814  0.253971 -0.513556  ... -0.621378  0.534853 -0.291514   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "0      -0.134794  0.165959  0.126280 -0.434824 -0.081230 -0.151045  0.858447  \n",
       "1       0.079469 -0.577395  0.190090  0.296503 -0.248052 -0.064512 -0.796369  \n",
       "2       0.945045 -1.154666 -0.605564 -0.312895 -0.300258 -0.244718 -1.377011  \n",
       "3      -0.214048 -1.893131  1.003963 -0.515950 -0.165316  0.048424 -0.962119  \n",
       "4      -0.161666  0.312561 -0.414116  1.071126  0.023712  0.419117  0.323285  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "568625  1.288249 -0.900861  0.560661 -0.006018  3.308968  0.081564 -1.105231  \n",
       "568626 -0.154257 -0.846452 -0.153443  1.961398 -1.528642  1.704306 -1.067766  \n",
       "568627 -0.211100 -0.448909  0.540073 -0.755836 -0.487540 -0.268741  1.666401  \n",
       "568628 -0.175488 -0.554643 -0.099669 -1.434931 -0.159269 -0.076251 -0.271853  \n",
       "568629  0.157303  0.931030 -0.349423 -1.090974 -1.575113  0.722936  1.365962  \n",
       "\n",
       "[568630 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_scaled_amount.drop('Class', axis=1) # Take only features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd983e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "568625    1\n",
       "568626    1\n",
       "568627    1\n",
       "568628    1\n",
       "568629    1\n",
       "Name: Class, Length: 568630, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_scaled_amount['Class'] # Take only targets\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2bf8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454904, 29)\n",
      "(454904,)\n",
      "(113726, 29)\n",
      "(113726,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Train test split with 80/20 split\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cabcda",
   "metadata": {},
   "source": [
    "## Creating Models With Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de53c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "lin_r = LinearRegression()\n",
    "log_r = LogisticRegression()\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# rf = RandomForestClassifier(max_depth=5, random_state=42)\n",
    "# NN =  MLPClassifier(alpha=1, max_iter=1000, random_state=42)\n",
    "# naive_bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17aee862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_r.fit(X_train, y_train)\n",
    "log_r.fit(X_train, y_train)\n",
    "# rf.fit(X_train, y_train)\n",
    "# knn.fit(np.array(X_train), np.array(y_train.values))\n",
    "# NN.fit(X_train, y_train)\n",
    "# naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f4be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs_and_intercept(model): # Print weights and bias of a given model\n",
    "    print('Coefs ->', model.coef_, end=\"\\n\\n\")\n",
    "    print('Intercept ->', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e89fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs -> [-0.05595133 -0.0329552  -0.08872454  0.1162398   0.01337336  0.02938414\n",
      "  0.02819934 -0.02188015  0.02598888 -0.02909242  0.05464137 -0.11582099\n",
      " -0.01200217 -0.17994644  0.00451989 -0.02457997  0.05589034  0.01809167\n",
      " -0.01355753  0.00801937  0.02791675  0.02250247 -0.02773597 -0.00278205\n",
      "  0.01417629 -0.02390846 -0.01606195  0.0196266   0.00023258]\n",
      "\n",
      "Intercept -> 0.49996645216201463\n"
     ]
    }
   ],
   "source": [
    "get_coefs_and_intercept(lin_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc008f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs -> [[-7.00115734e-01  1.57439425e-01 -1.19967412e+00  3.65597948e+00\n",
      "  -1.63486174e-02 -4.89014399e-01 -1.13380610e+00 -2.83115322e+00\n",
      "  -5.00608766e-01 -1.90859032e+00  1.87261096e+00 -2.83366756e+00\n",
      "   1.95770580e-02 -3.35903523e+00 -2.51350398e-01 -8.73108234e-01\n",
      "  -1.94995645e+00 -9.39612732e-01 -8.76435761e-02  1.26679902e-01\n",
      "   2.41520005e-01  4.23144774e-01 -3.31447005e-01 -1.71675329e-01\n",
      "   1.65847696e-01 -1.07839813e-01  1.84930259e-01  1.53131401e-01\n",
      "  -3.14021516e-03]]\n",
      "\n",
      "Intercept -> [9.17569964]\n"
     ]
    }
   ],
   "source": [
    "get_coefs_and_intercept(log_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e337830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model, x, y, model_type, data_type): # Print accuracy for a given model\n",
    "    print(data_type, 'accuracy for', model_type + ':', model.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fb38d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for Linear Regression: 0.7636401644730273\n",
      "Train accuracy for Logistic Regression: 0.9649200710479574\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "model_accuracy(lin_r, X_train, y_train, 'Linear Regression', 'Train')\n",
    "model_accuracy(log_r, X_train, y_train, 'Logistic Regression', 'Train')\n",
    "# model_accuracy(knn, X_train.values, y_train.values, 'KNN', 'Train') # KNN is slow. May take a bit to finish. 0.998\n",
    "# model_accuracy(rf, X_train, y_train, 'Random Forest', 'Train')\n",
    "# model_accuracy(NN, X_train, y_train, 'Neural Net', 'Train')\n",
    "# model_accuracy(naive_bayes, X_train, y_train, 'Naive Bayes', 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e82716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for Linear Regression: 0.7646516540315877\n",
      "Test accuracy for Logistic Regression: 0.9652761901412166\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "model_accuracy(lin_r, X_test, y_test, 'Linear Regression', 'Test')\n",
    "model_accuracy(log_r, X_test, y_test, 'Logistic Regression', 'Test')\n",
    "# model_accuracy(knn, X_test.values, y_test.values, 'KNN', 'Test') # KNN is a slow. May take a bit to finish. 0.997\n",
    "# model_accuracy(rf, X_test, y_test, 'Random Forest', 'Test')\n",
    "# model_accuracy(NN, X_test, y_test, 'Neural Net', 'Test')\n",
    "# model_accuracy(naive_bayes, X_test, y_test, 'Naive Bayes', 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dca77f",
   "metadata": {},
   "source": [
    "## Creating Models With Statmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "291f9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8276a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a previous iteration, noticed that some features have a high P-value (low significance)\n",
    "# These can be removed without drastically impacting the model impacting the model\n",
    "# Additionally, these values have coefficants close to 0, so keeping them will also not heavily influence the model\n",
    "df_removed = df_scaled_amount.copy()\n",
    "df_removed = df_removed.drop(['V5', 'Amount'], axis=1)\n",
    "X = df_removed.drop('Class', axis=1)\n",
    "y = df_removed['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb1d9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.094074\n",
      "         Iterations 12\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "log_statsmodel = sm.Logit(y, X).fit() # Create a logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e58bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_statsmodel = sm.OLS(y, X).fit() # Create a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60db4993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Class</td>      <th>  No. Observations:  </th>   <td>568630</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>568602</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    27</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 28 Feb 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.8643</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>07:19:23</td>     <th>  Log-Likelihood:    </th>  <td> -53493.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-3.9414e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td> 0.000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.0599</td> <td>    0.080</td> <td>  112.838</td> <td> 0.000</td> <td>    8.903</td> <td>    9.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>    <td>   -0.6825</td> <td>    0.018</td> <td>  -37.812</td> <td> 0.000</td> <td>   -0.718</td> <td>   -0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>    <td>    0.1628</td> <td>    0.016</td> <td>   10.299</td> <td> 0.000</td> <td>    0.132</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>    <td>   -1.1762</td> <td>    0.019</td> <td>  -60.581</td> <td> 0.000</td> <td>   -1.214</td> <td>   -1.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>    <td>    3.6329</td> <td>    0.027</td> <td>  135.882</td> <td> 0.000</td> <td>    3.580</td> <td>    3.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>    <td>   -0.4707</td> <td>    0.015</td> <td>  -32.325</td> <td> 0.000</td> <td>   -0.499</td> <td>   -0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>    <td>   -1.0991</td> <td>    0.024</td> <td>  -45.008</td> <td> 0.000</td> <td>   -1.147</td> <td>   -1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>    <td>   -2.8381</td> <td>    0.044</td> <td>  -63.970</td> <td> 0.000</td> <td>   -2.925</td> <td>   -2.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>    <td>   -0.4733</td> <td>    0.022</td> <td>  -21.755</td> <td> 0.000</td> <td>   -0.516</td> <td>   -0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>   <td>   -1.9053</td> <td>    0.031</td> <td>  -62.366</td> <td> 0.000</td> <td>   -1.965</td> <td>   -1.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>   <td>    1.8755</td> <td>    0.018</td> <td>  103.188</td> <td> 0.000</td> <td>    1.840</td> <td>    1.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>   <td>   -2.8143</td> <td>    0.026</td> <td> -109.701</td> <td> 0.000</td> <td>   -2.865</td> <td>   -2.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th>   <td>    0.0164</td> <td>    0.009</td> <td>    1.887</td> <td> 0.059</td> <td>   -0.001</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th>   <td>   -3.3562</td> <td>    0.026</td> <td> -127.257</td> <td> 0.000</td> <td>   -3.408</td> <td>   -3.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V15</th>   <td>   -0.2401</td> <td>    0.008</td> <td>  -28.263</td> <td> 0.000</td> <td>   -0.257</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V16</th>   <td>   -0.8487</td> <td>    0.024</td> <td>  -35.967</td> <td> 0.000</td> <td>   -0.895</td> <td>   -0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V17</th>   <td>   -1.9366</td> <td>    0.027</td> <td>  -72.118</td> <td> 0.000</td> <td>   -1.989</td> <td>   -1.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V18</th>   <td>   -0.9328</td> <td>    0.020</td> <td>  -45.692</td> <td> 0.000</td> <td>   -0.973</td> <td>   -0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V19</th>   <td>   -0.0784</td> <td>    0.012</td> <td>   -6.345</td> <td> 0.000</td> <td>   -0.103</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V20</th>   <td>    0.1342</td> <td>    0.012</td> <td>   11.057</td> <td> 0.000</td> <td>    0.110</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V21</th>   <td>    0.2504</td> <td>    0.028</td> <td>    8.812</td> <td> 0.000</td> <td>    0.195</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V22</th>   <td>    0.4402</td> <td>    0.015</td> <td>   29.079</td> <td> 0.000</td> <td>    0.411</td> <td>    0.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V23</th>   <td>   -0.3402</td> <td>    0.011</td> <td>  -31.927</td> <td> 0.000</td> <td>   -0.361</td> <td>   -0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V24</th>   <td>   -0.1646</td> <td>    0.009</td> <td>  -18.124</td> <td> 0.000</td> <td>   -0.182</td> <td>   -0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V25</th>   <td>    0.1620</td> <td>    0.011</td> <td>   14.938</td> <td> 0.000</td> <td>    0.141</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V26</th>   <td>   -0.1073</td> <td>    0.010</td> <td>  -10.968</td> <td> 0.000</td> <td>   -0.126</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V27</th>   <td>    0.1864</td> <td>    0.022</td> <td>    8.600</td> <td> 0.000</td> <td>    0.144</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V28</th>   <td>    0.1541</td> <td>    0.011</td> <td>   14.582</td> <td> 0.000</td> <td>    0.133</td> <td>    0.175</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.44 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &      Class       & \\textbf{  No. Observations:  } &    568630    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &    568602    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        27    \\\\\n",
       "\\textbf{Date:}            & Wed, 28 Feb 2024 & \\textbf{  Pseudo R-squ.:     } &    0.8643    \\\\\n",
       "\\textbf{Time:}            &     07:19:23     & \\textbf{  Log-Likelihood:    } &    -53493.   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } & -3.9414e+05  \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &     0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       9.0599  &        0.080     &   112.838  &         0.000        &        8.903    &        9.217     \\\\\n",
       "\\textbf{V1}    &      -0.6825  &        0.018     &   -37.812  &         0.000        &       -0.718    &       -0.647     \\\\\n",
       "\\textbf{V2}    &       0.1628  &        0.016     &    10.299  &         0.000        &        0.132    &        0.194     \\\\\n",
       "\\textbf{V3}    &      -1.1762  &        0.019     &   -60.581  &         0.000        &       -1.214    &       -1.138     \\\\\n",
       "\\textbf{V4}    &       3.6329  &        0.027     &   135.882  &         0.000        &        3.580    &        3.685     \\\\\n",
       "\\textbf{V6}    &      -0.4707  &        0.015     &   -32.325  &         0.000        &       -0.499    &       -0.442     \\\\\n",
       "\\textbf{V7}    &      -1.0991  &        0.024     &   -45.008  &         0.000        &       -1.147    &       -1.051     \\\\\n",
       "\\textbf{V8}    &      -2.8381  &        0.044     &   -63.970  &         0.000        &       -2.925    &       -2.751     \\\\\n",
       "\\textbf{V9}    &      -0.4733  &        0.022     &   -21.755  &         0.000        &       -0.516    &       -0.431     \\\\\n",
       "\\textbf{V10}   &      -1.9053  &        0.031     &   -62.366  &         0.000        &       -1.965    &       -1.845     \\\\\n",
       "\\textbf{V11}   &       1.8755  &        0.018     &   103.188  &         0.000        &        1.840    &        1.911     \\\\\n",
       "\\textbf{V12}   &      -2.8143  &        0.026     &  -109.701  &         0.000        &       -2.865    &       -2.764     \\\\\n",
       "\\textbf{V13}   &       0.0164  &        0.009     &     1.887  &         0.059        &       -0.001    &        0.033     \\\\\n",
       "\\textbf{V14}   &      -3.3562  &        0.026     &  -127.257  &         0.000        &       -3.408    &       -3.305     \\\\\n",
       "\\textbf{V15}   &      -0.2401  &        0.008     &   -28.263  &         0.000        &       -0.257    &       -0.223     \\\\\n",
       "\\textbf{V16}   &      -0.8487  &        0.024     &   -35.967  &         0.000        &       -0.895    &       -0.802     \\\\\n",
       "\\textbf{V17}   &      -1.9366  &        0.027     &   -72.118  &         0.000        &       -1.989    &       -1.884     \\\\\n",
       "\\textbf{V18}   &      -0.9328  &        0.020     &   -45.692  &         0.000        &       -0.973    &       -0.893     \\\\\n",
       "\\textbf{V19}   &      -0.0784  &        0.012     &    -6.345  &         0.000        &       -0.103    &       -0.054     \\\\\n",
       "\\textbf{V20}   &       0.1342  &        0.012     &    11.057  &         0.000        &        0.110    &        0.158     \\\\\n",
       "\\textbf{V21}   &       0.2504  &        0.028     &     8.812  &         0.000        &        0.195    &        0.306     \\\\\n",
       "\\textbf{V22}   &       0.4402  &        0.015     &    29.079  &         0.000        &        0.411    &        0.470     \\\\\n",
       "\\textbf{V23}   &      -0.3402  &        0.011     &   -31.927  &         0.000        &       -0.361    &       -0.319     \\\\\n",
       "\\textbf{V24}   &      -0.1646  &        0.009     &   -18.124  &         0.000        &       -0.182    &       -0.147     \\\\\n",
       "\\textbf{V25}   &       0.1620  &        0.011     &    14.938  &         0.000        &        0.141    &        0.183     \\\\\n",
       "\\textbf{V26}   &      -0.1073  &        0.010     &   -10.968  &         0.000        &       -0.126    &       -0.088     \\\\\n",
       "\\textbf{V27}   &       0.1864  &        0.022     &     8.600  &         0.000        &        0.144    &        0.229     \\\\\n",
       "\\textbf{V28}   &       0.1541  &        0.011     &    14.582  &         0.000        &        0.133    &        0.175     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.44 of observations can be \\newline\n",
       " perfectly predicted. This might indicate that there is complete \\newline\n",
       " quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   No. Observations:               568630\n",
       "Model:                          Logit   Df Residuals:                   568602\n",
       "Method:                           MLE   Df Model:                           27\n",
       "Date:                Wed, 28 Feb 2024   Pseudo R-squ.:                  0.8643\n",
       "Time:                        07:19:23   Log-Likelihood:                -53493.\n",
       "converged:                       True   LL-Null:                   -3.9414e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.0599      0.080    112.838      0.000       8.903       9.217\n",
       "V1            -0.6825      0.018    -37.812      0.000      -0.718      -0.647\n",
       "V2             0.1628      0.016     10.299      0.000       0.132       0.194\n",
       "V3            -1.1762      0.019    -60.581      0.000      -1.214      -1.138\n",
       "V4             3.6329      0.027    135.882      0.000       3.580       3.685\n",
       "V6            -0.4707      0.015    -32.325      0.000      -0.499      -0.442\n",
       "V7            -1.0991      0.024    -45.008      0.000      -1.147      -1.051\n",
       "V8            -2.8381      0.044    -63.970      0.000      -2.925      -2.751\n",
       "V9            -0.4733      0.022    -21.755      0.000      -0.516      -0.431\n",
       "V10           -1.9053      0.031    -62.366      0.000      -1.965      -1.845\n",
       "V11            1.8755      0.018    103.188      0.000       1.840       1.911\n",
       "V12           -2.8143      0.026   -109.701      0.000      -2.865      -2.764\n",
       "V13            0.0164      0.009      1.887      0.059      -0.001       0.033\n",
       "V14           -3.3562      0.026   -127.257      0.000      -3.408      -3.305\n",
       "V15           -0.2401      0.008    -28.263      0.000      -0.257      -0.223\n",
       "V16           -0.8487      0.024    -35.967      0.000      -0.895      -0.802\n",
       "V17           -1.9366      0.027    -72.118      0.000      -1.989      -1.884\n",
       "V18           -0.9328      0.020    -45.692      0.000      -0.973      -0.893\n",
       "V19           -0.0784      0.012     -6.345      0.000      -0.103      -0.054\n",
       "V20            0.1342      0.012     11.057      0.000       0.110       0.158\n",
       "V21            0.2504      0.028      8.812      0.000       0.195       0.306\n",
       "V22            0.4402      0.015     29.079      0.000       0.411       0.470\n",
       "V23           -0.3402      0.011    -31.927      0.000      -0.361      -0.319\n",
       "V24           -0.1646      0.009    -18.124      0.000      -0.182      -0.147\n",
       "V25            0.1620      0.011     14.938      0.000       0.141       0.183\n",
       "V26           -0.1073      0.010    -10.968      0.000      -0.126      -0.088\n",
       "V27            0.1864      0.022      8.600      0.000       0.144       0.229\n",
       "V28            0.1541      0.011     14.582      0.000       0.133       0.175\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.44 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_statsmodel.summary() # Good R-squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3cba0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th> <td>   0.764</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.764</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.804e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:20:10</td>     <th>  Log-Likelihood:    </th> <td> -2617.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>568630</td>      <th>  AIC:               </th> <td>   5291.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>568602</td>      <th>  BIC:               </th> <td>   5606.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5000</td> <td>    0.000</td> <td> 1551.001</td> <td> 0.000</td> <td>    0.499</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1</th>    <td>   -0.0563</td> <td>    0.000</td> <td> -120.319</td> <td> 0.000</td> <td>   -0.057</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>    <td>   -0.0375</td> <td>    0.001</td> <td>  -71.725</td> <td> 0.000</td> <td>   -0.039</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>    <td>   -0.0886</td> <td>    0.001</td> <td> -158.216</td> <td> 0.000</td> <td>   -0.090</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4</th>    <td>    0.1160</td> <td>    0.001</td> <td>  205.488</td> <td> 0.000</td> <td>    0.115</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6</th>    <td>    0.0272</td> <td>    0.000</td> <td>   54.571</td> <td> 0.000</td> <td>    0.026</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7</th>    <td>    0.0289</td> <td>    0.001</td> <td>   51.379</td> <td> 0.000</td> <td>    0.028</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V8</th>    <td>   -0.0254</td> <td>    0.001</td> <td>  -49.749</td> <td> 0.000</td> <td>   -0.026</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V9</th>    <td>    0.0256</td> <td>    0.001</td> <td>   46.205</td> <td> 0.000</td> <td>    0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>   <td>   -0.0278</td> <td>    0.001</td> <td>  -43.692</td> <td> 0.000</td> <td>   -0.029</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V11</th>   <td>    0.0557</td> <td>    0.001</td> <td>   94.064</td> <td> 0.000</td> <td>    0.055</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V12</th>   <td>   -0.1161</td> <td>    0.001</td> <td> -179.275</td> <td> 0.000</td> <td>   -0.117</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V13</th>   <td>   -0.0120</td> <td>    0.000</td> <td>  -34.533</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V14</th>   <td>   -0.1808</td> <td>    0.001</td> <td> -283.607</td> <td> 0.000</td> <td>   -0.182</td> <td>   -0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V15</th>   <td>    0.0047</td> <td>    0.000</td> <td>   13.622</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V16</th>   <td>   -0.0238</td> <td>    0.001</td> <td>  -33.351</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V17</th>   <td>    0.0599</td> <td>    0.001</td> <td>   74.409</td> <td> 0.000</td> <td>    0.058</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V18</th>   <td>    0.0203</td> <td>    0.001</td> <td>   31.516</td> <td> 0.000</td> <td>    0.019</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V19</th>   <td>   -0.0143</td> <td>    0.000</td> <td>  -31.254</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V20</th>   <td>    0.0074</td> <td>    0.000</td> <td>   17.214</td> <td> 0.000</td> <td>    0.007</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V21</th>   <td>    0.0287</td> <td>    0.001</td> <td>   47.113</td> <td> 0.000</td> <td>    0.027</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V22</th>   <td>    0.0231</td> <td>    0.001</td> <td>   43.448</td> <td> 0.000</td> <td>    0.022</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V23</th>   <td>   -0.0294</td> <td>    0.000</td> <td>  -73.193</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V24</th>   <td>   -0.0027</td> <td>    0.000</td> <td>   -7.798</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V25</th>   <td>    0.0139</td> <td>    0.000</td> <td>   36.785</td> <td> 0.000</td> <td>    0.013</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V26</th>   <td>   -0.0233</td> <td>    0.000</td> <td>  -68.787</td> <td> 0.000</td> <td>   -0.024</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V27</th>   <td>   -0.0157</td> <td>    0.000</td> <td>  -38.937</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V28</th>   <td>    0.0205</td> <td>    0.000</td> <td>   56.741</td> <td> 0.000</td> <td>    0.020</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>112627.992</td> <th>  Durbin-Watson:     </th>  <td>   1.522</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>421844.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 0.962</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 6.755</td>   <th>  Cond. No.          </th>  <td>    9.09</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Class       & \\textbf{  R-squared:         } &     0.764   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.764   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 6.804e+04   \\\\\n",
       "\\textbf{Date:}             & Wed, 28 Feb 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     07:20:10     & \\textbf{  Log-Likelihood:    } &   -2617.7   \\\\\n",
       "\\textbf{No. Observations:} &      568630      & \\textbf{  AIC:               } &     5291.   \\\\\n",
       "\\textbf{Df Residuals:}     &      568602      & \\textbf{  BIC:               } &     5606.   \\\\\n",
       "\\textbf{Df Model:}         &          27      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.5000  &        0.000     &  1551.001  &         0.000        &        0.499    &        0.501     \\\\\n",
       "\\textbf{V1}    &      -0.0563  &        0.000     &  -120.319  &         0.000        &       -0.057    &       -0.055     \\\\\n",
       "\\textbf{V2}    &      -0.0375  &        0.001     &   -71.725  &         0.000        &       -0.039    &       -0.037     \\\\\n",
       "\\textbf{V3}    &      -0.0886  &        0.001     &  -158.216  &         0.000        &       -0.090    &       -0.088     \\\\\n",
       "\\textbf{V4}    &       0.1160  &        0.001     &   205.488  &         0.000        &        0.115    &        0.117     \\\\\n",
       "\\textbf{V6}    &       0.0272  &        0.000     &    54.571  &         0.000        &        0.026    &        0.028     \\\\\n",
       "\\textbf{V7}    &       0.0289  &        0.001     &    51.379  &         0.000        &        0.028    &        0.030     \\\\\n",
       "\\textbf{V8}    &      -0.0254  &        0.001     &   -49.749  &         0.000        &       -0.026    &       -0.024     \\\\\n",
       "\\textbf{V9}    &       0.0256  &        0.001     &    46.205  &         0.000        &        0.025    &        0.027     \\\\\n",
       "\\textbf{V10}   &      -0.0278  &        0.001     &   -43.692  &         0.000        &       -0.029    &       -0.027     \\\\\n",
       "\\textbf{V11}   &       0.0557  &        0.001     &    94.064  &         0.000        &        0.055    &        0.057     \\\\\n",
       "\\textbf{V12}   &      -0.1161  &        0.001     &  -179.275  &         0.000        &       -0.117    &       -0.115     \\\\\n",
       "\\textbf{V13}   &      -0.0120  &        0.000     &   -34.533  &         0.000        &       -0.013    &       -0.011     \\\\\n",
       "\\textbf{V14}   &      -0.1808  &        0.001     &  -283.607  &         0.000        &       -0.182    &       -0.180     \\\\\n",
       "\\textbf{V15}   &       0.0047  &        0.000     &    13.622  &         0.000        &        0.004    &        0.005     \\\\\n",
       "\\textbf{V16}   &      -0.0238  &        0.001     &   -33.351  &         0.000        &       -0.025    &       -0.022     \\\\\n",
       "\\textbf{V17}   &       0.0599  &        0.001     &    74.409  &         0.000        &        0.058    &        0.061     \\\\\n",
       "\\textbf{V18}   &       0.0203  &        0.001     &    31.516  &         0.000        &        0.019    &        0.022     \\\\\n",
       "\\textbf{V19}   &      -0.0143  &        0.000     &   -31.254  &         0.000        &       -0.015    &       -0.013     \\\\\n",
       "\\textbf{V20}   &       0.0074  &        0.000     &    17.214  &         0.000        &        0.007    &        0.008     \\\\\n",
       "\\textbf{V21}   &       0.0287  &        0.001     &    47.113  &         0.000        &        0.027    &        0.030     \\\\\n",
       "\\textbf{V22}   &       0.0231  &        0.001     &    43.448  &         0.000        &        0.022    &        0.024     \\\\\n",
       "\\textbf{V23}   &      -0.0294  &        0.000     &   -73.193  &         0.000        &       -0.030    &       -0.029     \\\\\n",
       "\\textbf{V24}   &      -0.0027  &        0.000     &    -7.798  &         0.000        &       -0.003    &       -0.002     \\\\\n",
       "\\textbf{V25}   &       0.0139  &        0.000     &    36.785  &         0.000        &        0.013    &        0.015     \\\\\n",
       "\\textbf{V26}   &      -0.0233  &        0.000     &   -68.787  &         0.000        &       -0.024    &       -0.023     \\\\\n",
       "\\textbf{V27}   &      -0.0157  &        0.000     &   -38.937  &         0.000        &       -0.016    &       -0.015     \\\\\n",
       "\\textbf{V28}   &       0.0205  &        0.000     &    56.741  &         0.000        &        0.020    &        0.021     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 112627.992 & \\textbf{  Durbin-Watson:     } &     1.522   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000   & \\textbf{  Jarque-Bera (JB):  } & 421844.364  \\\\\n",
       "\\textbf{Skew:}          &    0.962   & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &    6.755   & \\textbf{  Cond. No.          } &      9.09   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   R-squared:                       0.764\n",
       "Model:                            OLS   Adj. R-squared:                  0.764\n",
       "Method:                 Least Squares   F-statistic:                 6.804e+04\n",
       "Date:                Wed, 28 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        07:20:10   Log-Likelihood:                -2617.7\n",
       "No. Observations:              568630   AIC:                             5291.\n",
       "Df Residuals:                  568602   BIC:                             5606.\n",
       "Df Model:                          27                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5000      0.000   1551.001      0.000       0.499       0.501\n",
       "V1            -0.0563      0.000   -120.319      0.000      -0.057      -0.055\n",
       "V2            -0.0375      0.001    -71.725      0.000      -0.039      -0.037\n",
       "V3            -0.0886      0.001   -158.216      0.000      -0.090      -0.088\n",
       "V4             0.1160      0.001    205.488      0.000       0.115       0.117\n",
       "V6             0.0272      0.000     54.571      0.000       0.026       0.028\n",
       "V7             0.0289      0.001     51.379      0.000       0.028       0.030\n",
       "V8            -0.0254      0.001    -49.749      0.000      -0.026      -0.024\n",
       "V9             0.0256      0.001     46.205      0.000       0.025       0.027\n",
       "V10           -0.0278      0.001    -43.692      0.000      -0.029      -0.027\n",
       "V11            0.0557      0.001     94.064      0.000       0.055       0.057\n",
       "V12           -0.1161      0.001   -179.275      0.000      -0.117      -0.115\n",
       "V13           -0.0120      0.000    -34.533      0.000      -0.013      -0.011\n",
       "V14           -0.1808      0.001   -283.607      0.000      -0.182      -0.180\n",
       "V15            0.0047      0.000     13.622      0.000       0.004       0.005\n",
       "V16           -0.0238      0.001    -33.351      0.000      -0.025      -0.022\n",
       "V17            0.0599      0.001     74.409      0.000       0.058       0.061\n",
       "V18            0.0203      0.001     31.516      0.000       0.019       0.022\n",
       "V19           -0.0143      0.000    -31.254      0.000      -0.015      -0.013\n",
       "V20            0.0074      0.000     17.214      0.000       0.007       0.008\n",
       "V21            0.0287      0.001     47.113      0.000       0.027       0.030\n",
       "V22            0.0231      0.001     43.448      0.000       0.022       0.024\n",
       "V23           -0.0294      0.000    -73.193      0.000      -0.030      -0.029\n",
       "V24           -0.0027      0.000     -7.798      0.000      -0.003      -0.002\n",
       "V25            0.0139      0.000     36.785      0.000       0.013       0.015\n",
       "V26           -0.0233      0.000    -68.787      0.000      -0.024      -0.023\n",
       "V27           -0.0157      0.000    -38.937      0.000      -0.016      -0.015\n",
       "V28            0.0205      0.000     56.741      0.000       0.020       0.021\n",
       "==============================================================================\n",
       "Omnibus:                   112627.992   Durbin-Watson:                   1.522\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           421844.364\n",
       "Skew:                           0.962   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.755   Cond. No.                         9.09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " lin_statsmodel.summary() # Lower R-squared value. Logistic model explains the data better than a Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ab8c0",
   "metadata": {},
   "source": [
    "## Creating Models With Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "721e808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = df_scaled_amount.drop('Class', axis = 1).shape[1] # Get total number of features\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "495a6a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = df_scaled_amount['Class'].nunique() # Get count of unique categories\n",
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0271c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.backend.clear_session() # Clear any previously saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feb65cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Hyper-parameters to fiddle with model\n",
    "learning_rate = .001\n",
    "hidden_layer_size = 100\n",
    "epochs = 10\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88ca2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #input layer\n",
    "    tf.keras.layers.Flatten(input_shape=(input_size,)),\n",
    "    \n",
    "    # Hidden layers\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    \n",
    "    # Output Layer\n",
    "    tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3edad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb43dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14216/14216 - 18s - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0060 - val_accuracy: 0.9984 - 18s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "14216/14216 - 17s - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0046 - val_accuracy: 0.9988 - 17s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "14216/14216 - 16s - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9990 - 16s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "14216/14216 - 16s - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9990 - 16s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "14216/14216 - 16s - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9993 - 16s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "14216/14216 - 16s - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9995 - 16s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "14216/14216 - 15s - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9996 - 15s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "14216/14216 - 15s - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995 - 15s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "14216/14216 - 15s - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995 - 15s/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279327b2a60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2) # Stop fitting after validation loss continues to increase after 2 iterations\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, verbose=2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7dd5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 - 2s - loss: 0.0032 - accuracy: 0.9995 - 2s/epoch - 679us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0032193181104958057, 0.9995076060295105]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2) # Test accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf11cc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 29)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               3000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,402\n",
      "Trainable params: 23,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # Print summary of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
